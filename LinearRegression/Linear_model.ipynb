{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:29:07.130954Z",
     "start_time": "2020-04-15T17:29:07.123649Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:29:09.220427Z",
     "start_time": "2020-04-15T17:29:08.964432Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('D:/DW1/New folder/GEE/GEE/data/danrer11_chopchop_train.csv',index_col=0)\n",
    "data_test = pd.read_csv('D:/DW1/New folder/GEE/GEE/data/danrer11_chopchop_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCGCGTAATGCTGGTTCTGCTGG', 'TGTGTTCACCCTGCGTCGAGTGG',\n",
       "       'TTCACAATGTCTTCTAATGCAGG', ..., 'AGGGGTGATTGTGTAAAAGCAGG',\n",
       "       'TAATAAAAATGACTTTAAAAAGG', 'GTTACTGTCGTGAGGGGGCGTGG'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['GUIDE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Data\n",
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:29:14.953865Z",
     "start_time": "2020-04-15T17:29:10.500645Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: (226420, 4, 23)\n",
      "Test dataset size: (56606, 4, 23)\n"
     ]
    }
   ],
   "source": [
    "encoding = {'A':np.array([1,0,0,0]),\n",
    "            'C':np.array([0,1,0,0]),\n",
    "            'G':np.array([0,0,1,0]),\n",
    "            'T':np.array([0,0,0,1])}\n",
    "\n",
    "def one_hot(guide,encoding):\n",
    "    data = np.zeros((4,len(guide)))\n",
    "    assert data.shape == (4,23)\n",
    "    for i in range(data.shape[-1]):\n",
    "        data[:,i] = encoding[guide[i]]\n",
    "    return data\n",
    "\n",
    "#print(one_hot('CTGATCACGGCTGAAGGACTCGG',encoding))\n",
    "\n",
    "def batch_one_hot(data,encoding):\n",
    "    guides = np.zeros((len(data),4,23))\n",
    "    i=0\n",
    "    for guide in data['GUIDE']:\n",
    "        guides[i] = one_hot(guide,encoding)\n",
    "        i+=1\n",
    "    return guides\n",
    "\n",
    "guides_train = batch_one_hot(data_train,encoding)\n",
    "guides_test = batch_one_hot(data_test,encoding)\n",
    "print('Train dataset size:',guides_train.shape)\n",
    "print('Test dataset size:',guides_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot('CTGATCACGGCTGAAGGACTCGG',encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pytorch` data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:30:21.903809Z",
     "start_time": "2020-04-15T17:30:21.875715Z"
    }
   },
   "outputs": [],
   "source": [
    "class GGEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample.float()\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "GGE_dataset_train = GGEDataset(data = guides_train, transform = transform)\n",
    "GGE_dataset_test = GGEDataset(data = guides_test, transform = transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(GGE_dataset_train, batch_size=50000,shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(GGE_dataset_test, batch_size=50000,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56606"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GGE_dataset_train)\n",
    "len(GGE_dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:30:32.433205Z",
     "start_time": "2020-04-15T17:30:32.421931Z"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(92, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 30)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(30, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 92),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.ConvTranspose2d(6, 1, 2)\n",
    "        self.pool2 =nn.MaxUnpool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,1*4*23)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(-1,1,4,23)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:30:50.862891Z",
     "start_time": "2020-04-15T17:30:50.856729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:30:54.766467Z",
     "start_time": "2020-04-15T17:30:54.744482Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T17:30:58.747124Z",
     "start_time": "2020-04-15T17:30:58.738679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('D:/DW1/New folder/GEE/GEE/model/autoencoder.pth.tar',map_location=torch.device('cpu'))\n",
    "net.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer all the guide from 92 dimension to 30 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(GGE_dataset_train, batch_size=len(GGE_dataset_train),shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(GGE_dataset_test, batch_size=len(GGE_dataset_test),shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        tr_fea = net.encoder(data.view(-1,1*4*23).to(device)).to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        test_fea = net.encoder(data.view(-1,1*4*23).to(device)).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneDataset(object):\n",
    "    def __init__(self, guide, eff):\n",
    "        self.target_sequence = guide\n",
    "        self.efficiency = eff.values\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.target_sequence[idx]\n",
    "        eff = torch.as_tensor(self.efficiency[idx], dtype=torch.float32)\n",
    "        return seq, eff\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(tr_fea))\n",
    "vali_size = len(tr_fea) - train_size\n",
    "\n",
    "tr = GeneDataset(tr_fea[:train_size],data_train['EFFICIENCY']/100)\n",
    "validation = GeneDataset(tr_fea[train_size:], data_train['EFFICIENCY']/100)\n",
    "test = GeneDataset(test_fea,data_test['EFFICIENCY']/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chop_trainloader = torch.utils.data.DataLoader(tr, batch_size=64,shuffle=True, num_workers=0)\n",
    "chop_validloader = torch.utils.data.DataLoader(validation, batch_size=64,shuffle=True, num_workers=0)\n",
    "chop_testloader = torch.utils.data.DataLoader(test, batch_size=64,shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch线性回归\n",
    "\n",
    "# 导入库\n",
    "import torch      \n",
    "from torch.autograd import Variable     \n",
    "import torch.nn as nn \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 创建LinearRegression类\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        # 超级函数，继承自nn.Module\n",
    "        super(LinearRegression,self).__init__()\n",
    "        # 线性函数\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )      \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )      \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        ) \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.75)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x);\n",
    "        x = self.layer2(x);\n",
    "        x = self.layer3(x);\n",
    "        x = self.layer4(x);\n",
    "        x = self.layer5(x);\n",
    "        x = self.layer6(x);\n",
    "        x = self.layer7(x);\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dim = tr[0][0].shape[0]\n",
    "input_dim = tr[0][0].shape[0]\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "input_dim = tr[0][0].shape[0]\n",
    "\n",
    "output_dim = 1\n",
    "\n",
    "#Linear Regression\n",
    "#model = LinearRegression(input_dim,output_dim) # 输入和输出大小为1\n",
    "#LSTM\n",
    "model = LinearRegression(input_dim, output_dim)\n",
    "\n",
    "# MSE/均方差\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 优化(找到最小化差值的参数)\n",
    "learning_rate = 0.0001  # 学习率, 达到最佳参数的速度有多快\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, trainloader, validloader,tolerance=0.0001):\n",
    "    valid_loss_his=[]\n",
    "    train_loss_his=[]\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epoch):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to('cpu'), targets.to('cpu')\n",
    "            outputs = model(inputs.view(inputs.shape[0],30))\n",
    "            loss = criterion(outputs[:,0], targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*inputs.size(0)\n",
    "\n",
    "        mean_loss = train_loss/(batch_idx+1)\n",
    "        train_loss_his.append(mean_loss)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (valid, tar) in enumerate(validloader):\n",
    "                valid, tar = valid.to('cpu'), tar.to('cpu')\n",
    "                opt = model(valid.view(valid.shape[0],30))\n",
    "                loss_2 = criterion(opt, tar)\n",
    "                valid_loss += loss_2.item()*valid.size(0)\n",
    "            mean_valid_loss = valid_loss/(batch_idx+1)\n",
    "            valid_loss_his.append(mean_valid_loss)\n",
    "        print('Train: Epoch: %d| train_loss: %f|valid_loss: %f'% (e, mean_loss, mean_valid_loss))\n",
    "        \n",
    "    return train_loss_his, valid_loss_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch: 0| train_loss: 1.611397|valid_loss: 1.048258\n",
      "Train: Epoch: 1| train_loss: 0.953535|valid_loss: 1.329936\n",
      "Train: Epoch: 2| train_loss: 0.450304|valid_loss: 1.627991\n",
      "Train: Epoch: 3| train_loss: 0.336516|valid_loss: 1.708515\n",
      "Train: Epoch: 4| train_loss: 0.294196|valid_loss: 1.702361\n",
      "Train: Epoch: 5| train_loss: 0.273434|valid_loss: 1.741056\n",
      "Train: Epoch: 6| train_loss: 0.260105|valid_loss: 1.783802\n",
      "Train: Epoch: 7| train_loss: 0.250303|valid_loss: 1.722392\n",
      "Train: Epoch: 8| train_loss: 0.243134|valid_loss: 1.797742\n",
      "Train: Epoch: 9| train_loss: 0.236582|valid_loss: 1.787264\n",
      "Train: Epoch: 10| train_loss: 0.231213|valid_loss: 1.775551\n",
      "Train: Epoch: 11| train_loss: 0.227882|valid_loss: 1.760367\n",
      "Train: Epoch: 12| train_loss: 0.223470|valid_loss: 1.828082\n",
      "Train: Epoch: 13| train_loss: 0.220583|valid_loss: 1.782933\n",
      "Train: Epoch: 14| train_loss: 0.217405|valid_loss: 1.790956\n",
      "Train: Epoch: 15| train_loss: 0.215983|valid_loss: 1.797386\n",
      "Train: Epoch: 16| train_loss: 0.213668|valid_loss: 1.794921\n",
      "Train: Epoch: 17| train_loss: 0.211932|valid_loss: 1.808226\n",
      "Train: Epoch: 18| train_loss: 0.210344|valid_loss: 1.814832\n",
      "Train: Epoch: 19| train_loss: 0.209242|valid_loss: 1.821228\n",
      "Train: Epoch: 20| train_loss: 0.207912|valid_loss: 1.792978\n",
      "Train: Epoch: 21| train_loss: 0.207301|valid_loss: 1.832198\n",
      "Train: Epoch: 22| train_loss: 0.206097|valid_loss: 1.828208\n",
      "Train: Epoch: 23| train_loss: 0.205920|valid_loss: 1.808166\n",
      "Train: Epoch: 24| train_loss: 0.204378|valid_loss: 1.814971\n",
      "Train: Epoch: 25| train_loss: 0.203791|valid_loss: 1.820442\n",
      "Train: Epoch: 26| train_loss: 0.203335|valid_loss: 1.804784\n",
      "Train: Epoch: 27| train_loss: 0.202146|valid_loss: 1.809181\n",
      "Train: Epoch: 28| train_loss: 0.202078|valid_loss: 1.828637\n",
      "Train: Epoch: 29| train_loss: 0.202201|valid_loss: 1.856894\n",
      "Train: Epoch: 30| train_loss: 0.201383|valid_loss: 1.833388\n",
      "Train: Epoch: 31| train_loss: 0.201224|valid_loss: 1.802086\n",
      "Train: Epoch: 32| train_loss: 0.200587|valid_loss: 1.834560\n",
      "Train: Epoch: 33| train_loss: 0.199577|valid_loss: 1.838077\n",
      "Train: Epoch: 34| train_loss: 0.199365|valid_loss: 1.815522\n",
      "Train: Epoch: 35| train_loss: 0.199038|valid_loss: 1.829397\n",
      "Train: Epoch: 36| train_loss: 0.198377|valid_loss: 1.797563\n",
      "Train: Epoch: 37| train_loss: 0.198716|valid_loss: 1.819953\n",
      "Train: Epoch: 38| train_loss: 0.197529|valid_loss: 1.821218\n",
      "Train: Epoch: 39| train_loss: 0.197502|valid_loss: 1.810757\n",
      "Train: Epoch: 40| train_loss: 0.197602|valid_loss: 1.824347\n",
      "Train: Epoch: 41| train_loss: 0.196995|valid_loss: 1.821197\n",
      "Train: Epoch: 42| train_loss: 0.196836|valid_loss: 1.817472\n",
      "Train: Epoch: 43| train_loss: 0.196709|valid_loss: 1.827571\n",
      "Train: Epoch: 44| train_loss: 0.196486|valid_loss: 1.834110\n",
      "Train: Epoch: 45| train_loss: 0.196256|valid_loss: 1.798838\n",
      "Train: Epoch: 46| train_loss: 0.195950|valid_loss: 1.828856\n",
      "Train: Epoch: 47| train_loss: 0.195915|valid_loss: 1.818950\n",
      "Train: Epoch: 48| train_loss: 0.195690|valid_loss: 1.815716\n",
      "Train: Epoch: 49| train_loss: 0.195236|valid_loss: 1.836478\n"
     ]
    }
   ],
   "source": [
    "train_loss_his, valid_loss_his = train(epoch=50, model=model, trainloader=chop_trainloader, validloader=chop_validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = list(range(1,len(train_loss_his)+1))\n",
    "\n",
    "plt.plot(x,train_loss_his, label='train loss')\n",
    "plt.plot(x,valid_loss_his, label='val loss')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('chopchop Training Monitoring')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUIDE</th>\n",
       "      <th>EFFICIENCY</th>\n",
       "      <th>CHR</th>\n",
       "      <th>STRAND</th>\n",
       "      <th>TSS</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229866</th>\n",
       "      <td>ATTAGTACGCGAACTCATAGCGG</td>\n",
       "      <td>55.34</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>62340897</td>\n",
       "      <td>62340956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110483</th>\n",
       "      <td>ACTGCAGTCGCGATTGGAGGAGG</td>\n",
       "      <td>44.18</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>49498262</td>\n",
       "      <td>49498344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>TCGGACAAGAAACTAGCTTTGGG</td>\n",
       "      <td>48.11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>15875002</td>\n",
       "      <td>15874883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244662</th>\n",
       "      <td>CAGCGGAGAAGAGGAGGCCGTGG</td>\n",
       "      <td>48.86</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13491501</td>\n",
       "      <td>13491645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222274</th>\n",
       "      <td>TAAATATGTAAAATATTTCAAGG</td>\n",
       "      <td>29.31</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>32274383</td>\n",
       "      <td>32274243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232791</th>\n",
       "      <td>ACAGAGTTCCAGCAGAAGTCAGG</td>\n",
       "      <td>46.99</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>10828881</td>\n",
       "      <td>10828852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196632</th>\n",
       "      <td>TGGTAAATAACAATTCTAGGCGG</td>\n",
       "      <td>68.78</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19665349</td>\n",
       "      <td>19665289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154340</th>\n",
       "      <td>TGAAGTAACTCACCAAACACTGG</td>\n",
       "      <td>55.47</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2789390</td>\n",
       "      <td>2789237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98521</th>\n",
       "      <td>CGCAGTATGGAGTATTTGATCGG</td>\n",
       "      <td>42.88</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>47405880</td>\n",
       "      <td>47405976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97147</th>\n",
       "      <td>CAAAAAGGGGGTTGGGTGCGAGG</td>\n",
       "      <td>47.77</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>42328430</td>\n",
       "      <td>42328392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56606 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          GUIDE  EFFICIENCY  CHR  STRAND       TSS  LOCATION\n",
       "229866  ATTAGTACGCGAACTCATAGCGG       55.34    5      -1  62340897  62340956\n",
       "110483  ACTGCAGTCGCGATTGGAGGAGG       44.18    1      -1  49498262  49498344\n",
       "13230   TCGGACAAGAAACTAGCTTTGGG       48.11   11       1  15875002  15874883\n",
       "244662  CAGCGGAGAAGAGGAGGCCGTGG       48.86    7       1  13491501  13491645\n",
       "222274  TAAATATGTAAAATATTTCAAGG       29.31    5      -1  32274383  32274243\n",
       "...                         ...         ...  ...     ...       ...       ...\n",
       "232791  ACAGAGTTCCAGCAGAAGTCAGG       46.99    6      -1  10828881  10828852\n",
       "196632  TGGTAAATAACAATTCTAGGCGG       68.78    3       1  19665349  19665289\n",
       "154340  TGAAGTAACTCACCAAACACTGG       55.47   23       1   2789390   2789237\n",
       "98521   CGCAGTATGGAGTATTTGATCGG       42.88   19       1  47405880  47405976\n",
       "97147   CAAAAAGGGGGTTGGGTGCGAGG       47.77   19       1  42328430  42328392\n",
       "\n",
       "[56606 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chop_pre = model(test_fea)\n",
    "data_test['pre'] = chop_pre.detach().numpy().reshape(1,-1)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EFFICIENCY</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229866</th>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.684398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110483</th>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.540777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.458814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244662</th>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.452292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222274</th>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.285216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232791</th>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.473956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196632</th>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.668666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154340</th>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.583181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98521</th>\n",
       "      <td>0.4288</td>\n",
       "      <td>0.484685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97147</th>\n",
       "      <td>0.4777</td>\n",
       "      <td>0.491554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56606 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EFFICIENCY       pre\n",
       "229866      0.5534  0.684398\n",
       "110483      0.4418  0.540777\n",
       "13230       0.4811  0.458814\n",
       "244662      0.4886  0.452292\n",
       "222274      0.2931  0.285216\n",
       "...            ...       ...\n",
       "232791      0.4699  0.473956\n",
       "196632      0.6878  0.668666\n",
       "154340      0.5547  0.583181\n",
       "98521       0.4288  0.484685\n",
       "97147       0.4777  0.491554\n",
       "\n",
       "[56606 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chop = data_test[['EFFICIENCY','pre']]\n",
    "df_chop['EFFICIENCY'] = df_chop['EFFICIENCY']/100\n",
    "#df_chop.to_csv('D:/DW1/New folder/results.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003089484618788134\n",
      "0.043058056283654195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true = df_chop['EFFICIENCY'].values.tolist()\n",
    "y_predict = df_chop['pre'].values.tolist()\n",
    "# MSE\n",
    "mse_predict = mean_squared_error(y_true, y_predict)\n",
    "# MAE\n",
    "mae_predict = mean_absolute_error(y_true, y_predict)\n",
    "print(mse_predict)\n",
    "print(mae_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = pd.read_csv(\"D:/DW1/New folder/GEE/GEE/data/danrer11_guide_results.txt\", sep=\"\\t\",usecols=[\"GUIDE\",\"qPCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUIDE</th>\n",
       "      <th>qPCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTGCCAAGTATAATGAGGAATGG</td>\n",
       "      <td>2.336301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTAGCATAGTCGTGTTTGGAGG</td>\n",
       "      <td>4.897509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCAAGTGAGACTTCGGAAAAAGG</td>\n",
       "      <td>2.432883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GAATGTGTATAAATCAGGCTTGG</td>\n",
       "      <td>0.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTCTGAAATCCACATCACCGTGG</td>\n",
       "      <td>-0.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>AGTAGAAGGCCCCGAATGCGTGG</td>\n",
       "      <td>-0.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TCACGTCCAAACCACCGGAGGGG</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>TCATCGGGCCATCCAGCAGCCGG</td>\n",
       "      <td>-0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>CAGACCGAAGAAGATGATGGAGG</td>\n",
       "      <td>0.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ATCTGCCAGAGTTCGCGCGGTGG</td>\n",
       "      <td>0.411805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GUIDE      qPCR\n",
       "0   GTGCCAAGTATAATGAGGAATGG  2.336301\n",
       "1   TGTAGCATAGTCGTGTTTGGAGG  4.897509\n",
       "2   CCAAGTGAGACTTCGGAAAAAGG  2.432883\n",
       "3   GAATGTGTATAAATCAGGCTTGG  0.196000\n",
       "4   CTCTGAAATCCACATCACCGTGG -0.341000\n",
       "..                      ...       ...\n",
       "58  AGTAGAAGGCCCCGAATGCGTGG -0.849000\n",
       "59  TCACGTCCAAACCACCGGAGGGG  0.625000\n",
       "60  TCATCGGGCCATCCAGCAGCCGG -0.508000\n",
       "61  CAGACCGAAGAAGATGATGGAGG  0.474000\n",
       "62  ATCTGCCAGAGTTCGCGCGGTGG  0.411805\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making preparation for transform learning \n",
    "Omax = 6.627324\n",
    "Omin = -2.29\n",
    "Nmin = 0\n",
    "Nmax = 1\n",
    "newlist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(loc_data)):\n",
    "    newlist.append(((Nmax-Nmin)/(Omax-Omin))*(loc_data.loc[i,\"qPCR\"] - Omin)+ Nmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUIDE</th>\n",
       "      <th>qPCR</th>\n",
       "      <th>qpcr_normalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTGCCAAGTATAATGAGGAATGG</td>\n",
       "      <td>2.336301</td>\n",
       "      <td>0.518799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TGTAGCATAGTCGTGTTTGGAGG</td>\n",
       "      <td>4.897509</td>\n",
       "      <td>0.806016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCAAGTGAGACTTCGGAAAAAGG</td>\n",
       "      <td>2.432883</td>\n",
       "      <td>0.529630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GAATGTGTATAAATCAGGCTTGG</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.278783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTCTGAAATCCACATCACCGTGG</td>\n",
       "      <td>-0.341000</td>\n",
       "      <td>0.218563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>AGTAGAAGGCCCCGAATGCGTGG</td>\n",
       "      <td>-0.849000</td>\n",
       "      <td>0.161596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TCACGTCCAAACCACCGGAGGGG</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.326892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>TCATCGGGCCATCCAGCAGCCGG</td>\n",
       "      <td>-0.508000</td>\n",
       "      <td>0.199836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>CAGACCGAAGAAGATGATGGAGG</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>0.309958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ATCTGCCAGAGTTCGCGCGGTGG</td>\n",
       "      <td>0.411805</td>\n",
       "      <td>0.302984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GUIDE      qPCR  qpcr_normalization\n",
       "0   GTGCCAAGTATAATGAGGAATGG  2.336301            0.518799\n",
       "1   TGTAGCATAGTCGTGTTTGGAGG  4.897509            0.806016\n",
       "2   CCAAGTGAGACTTCGGAAAAAGG  2.432883            0.529630\n",
       "3   GAATGTGTATAAATCAGGCTTGG  0.196000            0.278783\n",
       "4   CTCTGAAATCCACATCACCGTGG -0.341000            0.218563\n",
       "..                      ...       ...                 ...\n",
       "58  AGTAGAAGGCCCCGAATGCGTGG -0.849000            0.161596\n",
       "59  TCACGTCCAAACCACCGGAGGGG  0.625000            0.326892\n",
       "60  TCATCGGGCCATCCAGCAGCCGG -0.508000            0.199836\n",
       "61  CAGACCGAAGAAGATGATGGAGG  0.474000            0.309958\n",
       "62  ATCTGCCAGAGTTCGCGCGGTGG  0.411805            0.302984\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data[\"qpcr_normalization\"] = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(loc_data['GUIDE'])):\n",
    "    if len(loc_data['GUIDE'][i])!=23:\n",
    "        if len(loc_data['GUIDE'][i])==20:\n",
    "            loc_data['GUIDE'][i]=loc_data['GUIDE'][i]+'TGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dataset = GGEDataset(data = batch_one_hot(loc_data,encoding), transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(loc_dataset, batch_size=len(loc_dataset),shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([63, 30])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for data in dataloader:\n",
    "        loc_fea = net.encoder(data.view(-1,1*4*23).to(device)).to('cpu')\n",
    "print(\"Data shape: {}\".format(loc_fea.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(loc_dataset))\n",
    "test_size = len(loc_data) - train_size\n",
    "loc_tr = GeneDataset(loc_fea[:train_size],loc_data[\"qpcr_normalization\"][:train_size])\n",
    "loc_test = GeneDataset(loc_fea[train_size:],loc_data[\"qpcr_normalization\"][train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_trainloader = torch.utils.data.DataLoader(loc_tr, batch_size=32,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "loc_testloader = torch.utils.data.DataLoader(loc_test, batch_size=1,\n",
    "                                          shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch: 0| train_loss: 1.913568|valid_loss: 0.000000\n",
      "Train: Epoch: 1| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 2| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 3| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 4| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 5| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 6| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 7| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 8| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 9| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 10| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 11| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 12| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 13| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 14| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 15| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 16| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 17| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 18| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 19| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 20| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 21| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 22| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 23| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 24| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 25| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 26| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 27| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 28| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 29| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 30| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 31| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 32| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 33| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 34| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 35| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 36| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 37| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 38| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 39| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 40| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 41| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 42| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 43| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 44| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 45| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 46| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 47| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 48| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 49| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 50| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 51| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 52| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 53| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 54| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 55| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 56| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 57| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 58| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 59| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 60| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 61| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 62| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 63| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 64| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 65| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 66| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 67| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 68| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 69| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 70| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 71| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 72| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 73| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 74| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 75| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 76| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 77| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 78| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 79| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 80| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 81| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 82| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 83| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 84| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 85| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 86| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 87| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 88| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 89| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 90| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 91| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 92| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 93| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 94| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 95| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 96| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 97| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 98| train_loss: 1.383575|valid_loss: 0.000000\n",
      "Train: Epoch: 99| train_loss: 1.383575|valid_loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "input_dim = tr[0][0].shape[0]\n",
    "output_dim = 1\n",
    "model_without_tl = LinearRegression(input_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.0001 \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate, weight_decay=0.0001)\n",
    "train_loss_wtl, valid_loss_wtl = train(epoch=100, model=model_without_tl, trainloader=loc_trainloader, validloader=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data['Y_pre_no_tl'] = model_without_tl(loc_fea).detach().numpy().reshape(1,-1)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qpcr_normalization</th>\n",
       "      <th>Y_pre_no_tl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518799</td>\n",
       "      <td>0.479674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.478964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529630</td>\n",
       "      <td>0.479157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278783</td>\n",
       "      <td>0.480175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218563</td>\n",
       "      <td>0.477747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.479656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.326892</td>\n",
       "      <td>0.479006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.199836</td>\n",
       "      <td>0.479641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.309958</td>\n",
       "      <td>0.478251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.302984</td>\n",
       "      <td>0.479460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qpcr_normalization  Y_pre_no_tl\n",
       "0             0.518799     0.479674\n",
       "1             0.806016     0.478964\n",
       "2             0.529630     0.479157\n",
       "3             0.278783     0.480175\n",
       "4             0.218563     0.477747\n",
       "..                 ...          ...\n",
       "58            0.161596     0.479656\n",
       "59            0.326892     0.479006\n",
       "60            0.199836     0.479641\n",
       "61            0.309958     0.478251\n",
       "62            0.302984     0.479460\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data=loc_data[['qpcr_normalization','Y_pre_no_tl']]\n",
    "loc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06922521185732576\n",
      "0.2363171465150747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true_2 = loc_data['qpcr_normalization'].values.tolist()\n",
    "y_pred_2 = loc_data['Y_pre_no_tl'].values.tolist()\n",
    "\n",
    "# MSE\n",
    "mse_predict_2 = mean_squared_error(y_true_2, y_pred_2)\n",
    "# MAE\n",
    "mae_predict_2 = mean_absolute_error(y_true_2, y_pred_2)\n",
    "\n",
    "print(mse_predict_2)\n",
    "print(mae_predict_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Epoch: 0| train_loss: 2.456025|valid_loss: 0.000000\n",
      "Train: Epoch: 1| train_loss: 0.616803|valid_loss: 0.000000\n",
      "Train: Epoch: 2| train_loss: 0.612994|valid_loss: 0.000000\n",
      "Train: Epoch: 3| train_loss: 0.606865|valid_loss: 0.000000\n",
      "Train: Epoch: 4| train_loss: 0.601396|valid_loss: 0.000000\n",
      "Train: Epoch: 5| train_loss: 0.595274|valid_loss: 0.000000\n",
      "Train: Epoch: 6| train_loss: 0.588243|valid_loss: 0.000000\n",
      "Train: Epoch: 7| train_loss: 0.583359|valid_loss: 0.000000\n",
      "Train: Epoch: 8| train_loss: 0.577873|valid_loss: 0.000000\n",
      "Train: Epoch: 9| train_loss: 0.571804|valid_loss: 0.000000\n",
      "Train: Epoch: 10| train_loss: 0.567001|valid_loss: 0.000000\n",
      "Train: Epoch: 11| train_loss: 0.562670|valid_loss: 0.000000\n",
      "Train: Epoch: 12| train_loss: 0.560216|valid_loss: 0.000000\n",
      "Train: Epoch: 13| train_loss: 0.555444|valid_loss: 0.000000\n",
      "Train: Epoch: 14| train_loss: 0.551323|valid_loss: 0.000000\n",
      "Train: Epoch: 15| train_loss: 0.548822|valid_loss: 0.000000\n",
      "Train: Epoch: 16| train_loss: 0.543594|valid_loss: 0.000000\n",
      "Train: Epoch: 17| train_loss: 0.540301|valid_loss: 0.000000\n",
      "Train: Epoch: 18| train_loss: 0.535465|valid_loss: 0.000000\n",
      "Train: Epoch: 19| train_loss: 0.530692|valid_loss: 0.000000\n",
      "Train: Epoch: 20| train_loss: 0.525697|valid_loss: 0.000000\n",
      "Train: Epoch: 21| train_loss: 0.520582|valid_loss: 0.000000\n",
      "Train: Epoch: 22| train_loss: 0.515667|valid_loss: 0.000000\n",
      "Train: Epoch: 23| train_loss: 0.511027|valid_loss: 0.000000\n",
      "Train: Epoch: 24| train_loss: 0.506085|valid_loss: 0.000000\n",
      "Train: Epoch: 25| train_loss: 0.501423|valid_loss: 0.000000\n",
      "Train: Epoch: 26| train_loss: 0.496506|valid_loss: 0.000000\n",
      "Train: Epoch: 27| train_loss: 0.492402|valid_loss: 0.000000\n",
      "Train: Epoch: 28| train_loss: 0.487920|valid_loss: 0.000000\n",
      "Train: Epoch: 29| train_loss: 0.483283|valid_loss: 0.000000\n",
      "Train: Epoch: 30| train_loss: 0.479447|valid_loss: 0.000000\n",
      "Train: Epoch: 31| train_loss: 0.473211|valid_loss: 0.000000\n",
      "Train: Epoch: 32| train_loss: 0.468157|valid_loss: 0.000000\n",
      "Train: Epoch: 33| train_loss: 0.465092|valid_loss: 0.000000\n",
      "Train: Epoch: 34| train_loss: 0.459797|valid_loss: 0.000000\n",
      "Train: Epoch: 35| train_loss: 0.455301|valid_loss: 0.000000\n",
      "Train: Epoch: 36| train_loss: 0.450783|valid_loss: 0.000000\n",
      "Train: Epoch: 37| train_loss: 0.446116|valid_loss: 0.000000\n",
      "Train: Epoch: 38| train_loss: 0.441577|valid_loss: 0.000000\n",
      "Train: Epoch: 39| train_loss: 0.438555|valid_loss: 0.000000\n",
      "Train: Epoch: 40| train_loss: 0.432607|valid_loss: 0.000000\n",
      "Train: Epoch: 41| train_loss: 0.427966|valid_loss: 0.000000\n",
      "Train: Epoch: 42| train_loss: 0.422608|valid_loss: 0.000000\n",
      "Train: Epoch: 43| train_loss: 0.418849|valid_loss: 0.000000\n",
      "Train: Epoch: 44| train_loss: 0.413496|valid_loss: 0.000000\n",
      "Train: Epoch: 45| train_loss: 0.408488|valid_loss: 0.000000\n",
      "Train: Epoch: 46| train_loss: 0.403392|valid_loss: 0.000000\n",
      "Train: Epoch: 47| train_loss: 0.399859|valid_loss: 0.000000\n",
      "Train: Epoch: 48| train_loss: 0.393627|valid_loss: 0.000000\n",
      "Train: Epoch: 49| train_loss: 0.388616|valid_loss: 0.000000\n",
      "Train: Epoch: 50| train_loss: 0.384296|valid_loss: 0.000000\n",
      "Train: Epoch: 51| train_loss: 0.378621|valid_loss: 0.000000\n",
      "Train: Epoch: 52| train_loss: 0.375213|valid_loss: 0.000000\n",
      "Train: Epoch: 53| train_loss: 0.370337|valid_loss: 0.000000\n",
      "Train: Epoch: 54| train_loss: 0.364870|valid_loss: 0.000000\n",
      "Train: Epoch: 55| train_loss: 0.360823|valid_loss: 0.000000\n",
      "Train: Epoch: 56| train_loss: 0.355554|valid_loss: 0.000000\n",
      "Train: Epoch: 57| train_loss: 0.350466|valid_loss: 0.000000\n",
      "Train: Epoch: 58| train_loss: 0.345648|valid_loss: 0.000000\n",
      "Train: Epoch: 59| train_loss: 0.341075|valid_loss: 0.000000\n",
      "Train: Epoch: 60| train_loss: 0.337283|valid_loss: 0.000000\n",
      "Train: Epoch: 61| train_loss: 0.332916|valid_loss: 0.000000\n",
      "Train: Epoch: 62| train_loss: 0.329724|valid_loss: 0.000000\n",
      "Train: Epoch: 63| train_loss: 0.325620|valid_loss: 0.000000\n",
      "Train: Epoch: 64| train_loss: 0.321905|valid_loss: 0.000000\n",
      "Train: Epoch: 65| train_loss: 0.317652|valid_loss: 0.000000\n",
      "Train: Epoch: 66| train_loss: 0.314261|valid_loss: 0.000000\n",
      "Train: Epoch: 67| train_loss: 0.310876|valid_loss: 0.000000\n",
      "Train: Epoch: 68| train_loss: 0.306496|valid_loss: 0.000000\n",
      "Train: Epoch: 69| train_loss: 0.302199|valid_loss: 0.000000\n",
      "Train: Epoch: 70| train_loss: 0.299200|valid_loss: 0.000000\n",
      "Train: Epoch: 71| train_loss: 0.295239|valid_loss: 0.000000\n",
      "Train: Epoch: 72| train_loss: 0.292299|valid_loss: 0.000000\n",
      "Train: Epoch: 73| train_loss: 0.287971|valid_loss: 0.000000\n",
      "Train: Epoch: 74| train_loss: 0.283774|valid_loss: 0.000000\n",
      "Train: Epoch: 75| train_loss: 0.280388|valid_loss: 0.000000\n",
      "Train: Epoch: 76| train_loss: 0.278202|valid_loss: 0.000000\n",
      "Train: Epoch: 77| train_loss: 0.274261|valid_loss: 0.000000\n",
      "Train: Epoch: 78| train_loss: 0.270545|valid_loss: 0.000000\n",
      "Train: Epoch: 79| train_loss: 0.267320|valid_loss: 0.000000\n",
      "Train: Epoch: 80| train_loss: 0.264275|valid_loss: 0.000000\n",
      "Train: Epoch: 81| train_loss: 0.260790|valid_loss: 0.000000\n",
      "Train: Epoch: 82| train_loss: 0.256744|valid_loss: 0.000000\n",
      "Train: Epoch: 83| train_loss: 0.255224|valid_loss: 0.000000\n",
      "Train: Epoch: 84| train_loss: 0.251768|valid_loss: 0.000000\n",
      "Train: Epoch: 85| train_loss: 0.249264|valid_loss: 0.000000\n",
      "Train: Epoch: 86| train_loss: 0.245957|valid_loss: 0.000000\n",
      "Train: Epoch: 87| train_loss: 0.242305|valid_loss: 0.000000\n",
      "Train: Epoch: 88| train_loss: 0.239048|valid_loss: 0.000000\n",
      "Train: Epoch: 89| train_loss: 0.234947|valid_loss: 0.000000\n",
      "Train: Epoch: 90| train_loss: 0.231559|valid_loss: 0.000000\n",
      "Train: Epoch: 91| train_loss: 0.228062|valid_loss: 0.000000\n",
      "Train: Epoch: 92| train_loss: 0.225305|valid_loss: 0.000000\n",
      "Train: Epoch: 93| train_loss: 0.222382|valid_loss: 0.000000\n",
      "Train: Epoch: 94| train_loss: 0.219091|valid_loss: 0.000000\n",
      "Train: Epoch: 95| train_loss: 0.216037|valid_loss: 0.000000\n",
      "Train: Epoch: 96| train_loss: 0.213267|valid_loss: 0.000000\n",
      "Train: Epoch: 97| train_loss: 0.210308|valid_loss: 0.000000\n",
      "Train: Epoch: 98| train_loss: 0.207769|valid_loss: 0.000000\n",
      "Train: Epoch: 99| train_loss: 0.204968|valid_loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "input_dim = tr[0][0].shape[0]\n",
    "output_dim = 1\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.0001 \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate, weight_decay=0.0001)\n",
    "train_loss_tl, valid_loss_tl = train(epoch=100, model=model, trainloader=loc_trainloader, validloader=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qpcr_normalization</th>\n",
       "      <th>Y_pre_no_tl</th>\n",
       "      <th>Y_pre_tl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518799</td>\n",
       "      <td>0.479674</td>\n",
       "      <td>0.396665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.478964</td>\n",
       "      <td>0.564521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529630</td>\n",
       "      <td>0.479157</td>\n",
       "      <td>0.432652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278783</td>\n",
       "      <td>0.480175</td>\n",
       "      <td>0.265790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218563</td>\n",
       "      <td>0.477747</td>\n",
       "      <td>0.212053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.479656</td>\n",
       "      <td>0.280492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.326892</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.364159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.199836</td>\n",
       "      <td>0.479641</td>\n",
       "      <td>0.273505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.309958</td>\n",
       "      <td>0.478251</td>\n",
       "      <td>0.357890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.302984</td>\n",
       "      <td>0.479460</td>\n",
       "      <td>0.326865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qpcr_normalization  Y_pre_no_tl  Y_pre_tl\n",
       "0             0.518799     0.479674  0.396665\n",
       "1             0.806016     0.478964  0.564521\n",
       "2             0.529630     0.479157  0.432652\n",
       "3             0.278783     0.480175  0.265790\n",
       "4             0.218563     0.477747  0.212053\n",
       "..                 ...          ...       ...\n",
       "58            0.161596     0.479656  0.280492\n",
       "59            0.326892     0.479006  0.364159\n",
       "60            0.199836     0.479641  0.273505\n",
       "61            0.309958     0.478251  0.357890\n",
       "62            0.302984     0.479460  0.326865\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data['Y_pre_tl'] = model(loc_fea).detach().numpy().reshape(1,-1)[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"D:/DW1/final/LinearRegressionmodel.pth\") \n",
    "torch.save(model.state_dict(), \"D:/DW1/final/LinearRegressionmodel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021519254160998317\n",
      "0.09619318315202804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_true_3 = loc_data['qpcr_normalization'].values.tolist()\n",
    "y_pred_3 = loc_data['Y_pre_tl'].values.tolist()\n",
    "\n",
    "# MSE\n",
    "mse_predict_3 = mean_squared_error(y_true_3, y_pred_3)\n",
    "# MAE\n",
    "mae_predict_3 = mean_absolute_error(y_true_3, y_pred_3)\n",
    "\n",
    "\n",
    "\n",
    "print(mse_predict_3)\n",
    "print(mae_predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = list(range(1,len(train_loss_wtl)+1))\n",
    "\n",
    "plt.plot(x,train_loss_wtl, label='train loss without transfer learning')\n",
    "plt.plot(x,train_loss_tl, label='train loss using transfer learning')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Comparison of transfer learning effects')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qpcr_normalization</th>\n",
       "      <th>Y_pre_no_tl</th>\n",
       "      <th>Y_pre_tl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518799</td>\n",
       "      <td>0.536637</td>\n",
       "      <td>0.319077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.535257</td>\n",
       "      <td>0.408827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529630</td>\n",
       "      <td>0.535424</td>\n",
       "      <td>0.342157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278783</td>\n",
       "      <td>0.535128</td>\n",
       "      <td>0.298286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218563</td>\n",
       "      <td>0.533776</td>\n",
       "      <td>0.275530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.535046</td>\n",
       "      <td>0.314670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.326892</td>\n",
       "      <td>0.535993</td>\n",
       "      <td>0.324730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.199836</td>\n",
       "      <td>0.533669</td>\n",
       "      <td>0.283016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.309958</td>\n",
       "      <td>0.532644</td>\n",
       "      <td>0.300362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.302984</td>\n",
       "      <td>0.533858</td>\n",
       "      <td>0.295352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qpcr_normalization  Y_pre_no_tl  Y_pre_tl\n",
       "0             0.518799     0.536637  0.319077\n",
       "1             0.806016     0.535257  0.408827\n",
       "2             0.529630     0.535424  0.342157\n",
       "3             0.278783     0.535128  0.298286\n",
       "4             0.218563     0.533776  0.275530\n",
       "..                 ...          ...       ...\n",
       "58            0.161596     0.535046  0.314670\n",
       "59            0.326892     0.535993  0.324730\n",
       "60            0.199836     0.533669  0.283016\n",
       "61            0.309958     0.532644  0.300362\n",
       "62            0.302984     0.533858  0.295352\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data.to_csv('D:/DW1/New folder/results.csv',index=False, header=True)\n",
    "loc_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
